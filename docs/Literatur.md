| **Judul**                                                                                                                                                                                       | **Peneliti, Media Publikasi dan Tahun**                                                                                                          | **Tujuan Penelitian**                                                                                                                                                                                                                                             | **Kesimpulan**                                                                                                                                                                                                                                                                                                                          | **Saran atau Kelemahan**                                                                                                                                                                                                                                                            | **Perbandingan**                                                                                                                                                                                    |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **LEAF-YOLO: Lightweight Edge-Real-Time Small Object Detection on Aerial Imagery**                                                                                                              | Nghiem Van Quang, Nguyen Huy Hoang, Hoang Minh Son,Intelligent Systems with Applications (2025)                                                       | **Mengatasi tantangan deteksi objek kecil dalam citra UAV (Unmanned Aerial Vehicle) dengan sumber daya komputasi terbatas pada perangkat***edge*dengan mengembangkan algoritma yang ringan dan efisien.                                                         | **LEAF-YOLO**dan**LEAF-YOLO-N**mengungguli model dengan parameter < 20M dalam akurasi dan efisiensi pada dataset Visdrone2019-DET-val, berjalan*real-time*(>30 FPS) pada Jetson AGX Xavier.^3^^3^^3^^3^                                                                                                                         | Model memiliki keterbatasan dalam kondisi ekstrim (cahaya malam, bayangan) dan skenario padat/tumpang tindih.**Diperlukan pengembangan lebih lanjut untuk menangani bentuk tidak teratur dan oklusi parsial.                                                                              | **LEAF-YOLO**mencapai 28.2%**$AP_{50:95}$**dan 48.3%**$AP_{50}$**(4.28M parameter), mengungguli model sejenis.                                                                      |
| **VBP-YOLO-prune: Robust apple detection under variable weather via feature-adaptive fusion and efficient YOLO pruning**                                                                        | Haohai You, Hao Wang, Zhanchen Wei, Chunguang Bi, Lijuan Zhang, Xuefang Li, Yingying Yin,Alexandria Engineering Journal (2025)                         | **Mengembangkan model deteksi apel yang ringan dan kokoh (** **VBP-YOLO-prune** **) untuk robot pemetik di lingkungan kebun yang kompleks dengan berbagai cuaca, fokus pada akurasi dan efisiensi***edge* *deployment* **.**                | **VBP-YOLO-prune**mencapai 89.0% mAP50 dan 66.26% mAP50-95, dengan pengurangan parameter 79.7% dan FLOPs 60.9% dibandingkan YOLOv8n.^9^Model berjalan pada 102.6 FPS di NVIDIA Jetson Orin Nano.^10^                                                                                                                                    | **Model masih menghadapi tantangan dalam menangani gambar resolusi tinggi/dataset besar dan terpengaruh faktor lingkungan (cahaya, oklusi).**^11^Perlu peningkatan deteksi target kecil jarak jauh/objek warna serupa.^12^                                                          | **VBP-YOLO-prune**memiliki 0.61M parameter, 3.2 GFLOPs, dan 102.6 FPS, mengungguli model*lightweight*SOTA lainnya (e.g., YOLOv11n, YOLOv12n) dalam akurasi dan efisiensi.                         |
| **Hybrid-YOLO: Lightweight Mamba-Transformer Hybrid with Multi-Scale Fusion for Real-World Traffic Detection**                                                                                  | Hongqing Wang, JunKit Chaw, Marizuana Mat Daud, Liantao Shi, Nannan Huang, Tin Tin Ting, Liuzhen Pu,ICT Express (2025)                                 | **Mengembangkan***framework*deteksi lalu lintas*real-time*yang ringan ( **Hybrid-YOLO** **) dengan menggabungkan Mamba-SSM (State Space Model) dan Transformer untuk mengatasi oklusi, variasi pencahayaan, dan cuaca ekstrem.**                  | **Hybrid-YOLO**mencapai 90.11% mAP@0.5 pada 66.3 FPS, melampaui metode*state-of-the-art*(SOTA) dalam akurasi dan efisiensi di dataset campuran (KITTI, BDD100K, IITM-HeTra).^16^^16^^16^^16^^16^^16^^16^                                                                                                                              | **Fokus masa depan adalah mengurangi***overhead*komputasi lebih lanjut melalui*model pruning*dan menguji di skenario ITS yang lebih kompleks.^17^                                                                                                                               | **Hybrid-YOLO**(55.3M Params) mencapai 90.11% mAP@0.5, melampaui YOLOv11x (57.0M Params, 84.73% mAP@0.5) dan RepViT (14.0M Params, 87.11% mAP@0.5).                                                 |
| **YOLO-ARM: An enhanced YOLOv7 framework with adaptive attention receptive module for high-precision robotic vision object detection**                                                          | Fuzhi Wang, Changlin Song,Alexandria Engineering Journal (2025)                                                                                       | **Mengatasi masalah presisi deteksi rendah, kinerja***real-time*suboptimal, dan generalisasi model yang buruk dalam sistem visi robotik di bawah kondisi buruk dengan mengusulkan arsitektur YOLOv7 yang ditingkatkan ( **YOLO-ARM** **).**         | **YOLO-ARM**mengungguli model lain di dataset MS COCO, mencapai F1-score 98.60%, presisi 97.997%, dan akurasi 99.727%.^21^^21^^21^^21^                                                                                                                                                                                                  | **Penambahan modul perhatian (ARM dan CBAM) meningkatkan kompleksitas pelatihan dan waktu konvergensi, membutuhkan upaya komputasi dan***epoch*ekstra.^22^Perlu optimasi*memory handling*untuk*dataset*skala besar.^23^                                                       | **YOLO-ARM**mencapai akurasi 99.73%, jauh melampaui CNN (93.51%), R-CNN (93.53%), YOLOv5 (92.83%), dan FPN (93.52%).                                                                                |
| **CMD-YOLO: A lightweight model for cherry maturity detection targeting small object**                                                                                                          | Meng Li, Xue Ding, Jinliang Wang,Smart Agricultural Technology (2025)                                                                                  | **Mengatasi tiga tantangan inti deteksi kematangan ceri: interferensi lingkungan, deteksi target kecil yang padat, dan beban komputasi tinggi untuk***edge* *deployment* **, dengan mengusulkan model ringan**CMD-YOLO**berbasis YOLOv12.               | **CMD-YOLO**meningkatkan akurasi deteksi menjadi 70.7%,*recall*70.0%, mAP50 74.3%, dan mAP50:95 54.9% dibandingkan*baseline*YOLOv12, sambil mengurangi parameter menjadi 0.7M (turun 73.1%).^27^                                                                                                                                    | **Kinerja model di bawah kondisi yang sangat kompleks (asap tebal/oklusi multi-lapisan) masih perlu ditingkatkan.**^28^Perlu eksplorasi fusi data*multimodal*untuk target sangat kecil/buram.^29^Belum ada perbandingan SOTA*lightweight*seperti PP-PicoDet/NanoDet.^30^        | **CMD-YOLO**(0.674M Params, 7.7 GFLOPs) melampaui YOLOv12n ( *baseline* **, 2.557M Params, 6.3 GFLOPs) di semua metrik akurasi utama.**                                                     |
| **YOLO-MEST: a re-parameterized multi-scale fusion model with enhanced detection head for high-accuracy tea bud detection**                                                                     | Chuanyang Yu, Yi Xue, Liuyang Zhang, Xue An, Ce Liu, Liqing Chen, Information Processing in Agriculture (2025)                                        | **Mencapai pengenalan kuncup teh yang akurat untuk pemanenan otomatis, mengatasi tantangan kondisi lapangan yang kompleks (cahaya, oklusi, latar belakang berantakan).**                                                                                          | **YOLO-MEST**meningkatkan mAP50 sebesar 1.7% dan mAP sebesar 4.4% dibandingkan model YOLOv8 asli.^34^Model penuh mencapai 84.9% mAP50 dengan peningkatan*overhead*komputasi hanya 8%.^35^                                                                                                                                             | **Kompleksitas komputasi model (10.9 GFLOPs) masih menjadi tantangan untuk***deployment*di perangkat *ultra-low-power* **.**^36^Kinerja di bawah kondisi cuaca ekstrem atau kultivar teh yang berbeda memerlukan penyelidikan lebih lanjut.^37^                           | **YOLO-MEST-n**mencapai 84.9% mAP50, 1.7% lebih tinggi dari YOLOv8-n ( *baseline* **).**                                                                                                    |
| **YOLO-MP: A lightweight forest fire detection model**                                                                                                                                          | Hongwei Zhu, Weiwei Ling, Huabiao Yan, Xinghai Zhong, Feng Liao,*Ecological Informatics*(2025)                                                       | **Mengatasi inefisiensi dan akurasi rendah dari metode tradisional serta kelemahan model***deep learning*yang ada (ekstraksi fitur dan*lightweighting*yang tidak memadai) untuk deteksi kebakaran hutan.                                                      | **YOLO-MP**meningkatkan *recall* **, mAP50, dan mAP50-95 sebesar 2.76%, 1.52%, dan 1.18% dibandingkan** *baseline* **.**^41^Model hanya memiliki 2.07M parameter (pengurangan 31%) dan 6.02 GFLOPs (penurunan 26%).^42^                                                                                                 | **Perluasan***dataset*dengan citra*multimodal*(inframerah, kamera kedalaman) disarankan.^43^Perlu optimasi lebih lanjut untuk mengatasi kabut asap padat atau oklusi vegetasi multi-lapisan.^44^                                                                                | **YOLO-MP**(2.07M Params, 6.02 GFLOPs) mengungguli YOLOv8n ( *baseline* **, 3.01M Params, 8.09 GFLOPs) di semua metrik akurasi, sambil lebih ringan.**                                      |
| **YOLO-FCAP: An improved lightweight object detection model based on YOLOv8n for citrus yield prediction in complex environments**                                                              | Tiwei Zeng, Jintao Tong, Xudong Sun, Jiacheng Liu, Xiangguo He, Zhenzhen Guan, Lingfeng Liu, Nan Jiang, Tao wan, Smart Agricultural Technology (2025) | **Mengembangkan model ringan (** **YOLO-FCAP** **) untuk deteksi objek dan prediksi hasil panen jeruk yang akurat dan efisien di lingkungan kebun yang kompleks, mengatasi oklusi dan keterbatasan perangkat** *edge* **.**                   | **YOLO-FCAP**mengurangi parameter dan FLOPs menjadi 0.81M dan 5.5 G.^48^Presisi, *recall* **, dan AP mencapai 90.4%, 84.3%, dan 92.5%, dengan FPS 168.42.**^49^Persamaan regresi linier memprediksi hasil panen dengan kinerja yang sangat baik (**$R^{2}=0.983$**,**$MAE=0.95$**,**$RMSE=1.20$**).^50^ | **Model masih menghadapi tantangan***false*dan *missed detections* **, terutama pada oklusi berlebihan.**^51^Pengambilan gambar hanya dengan kamera*smartphone*membatasi sudut pandang.^52^Perlu diperkuat ketahanan terhadap kondisi cuaca kompleks (hujan/kabut).^53^ | **YOLO-FCAP**(0.81M Params, 5.5 GFLOPs, 168.42 FPS) mengungguli model*lightweight*SOTA (e.g., YOLOv11n, YOLOv10n, YOLOv5n) dalam hal AP dan efisiensi model.                                      |
| **CD-VIT-YOLO: A lightweight Hybrid ViT-YOLO model for caged duck behaviour recognition under varying lighting conditions**                                                                     | Yujin Gong, Gen Zhang, Chuntao Wang, Deqin Xiao,Smart Agricultural Technology (2025)                                                                   | **Mengembangkan model***lightweight**hybrid*ViT-YOLO ( **CD-VIT-YOLO** **) untuk pengenalan perilaku bebek yang dikandang dalam berbagai kondisi pencahayaan, mengatasi masalah oklusi dan variasi cahaya.**                                        | **CD-VIT-YOLO**mencapai 97.4% mAP@0.5 dan 88.6% mAP@0.5:0.95, 2.3% lebih tinggi dari YOLOv5s dengan pengurangan parameter 32% dan GFLOPs 45%.^57^                                                                                                                                                                                       | **Kinerja model menurun pada kondisi cahaya rendah (malam hari).**^58^Perlu mengatasi ambiguitas semantik antar perilaku (mis. "minum" vs. "mematuk") dan kebisingan label.^59^                                                                                                     | **CD-VIT-YOLO**(4.75M Params, 8.7 GFLOPs) melampaui YOLOv5s ( *baseline* **) dan bahkan model terbaru seperti YOLOv12s dalam mAP@0.5:0.95.**                                                |
| **An improved small object detection CTB-YOLO model for early detection of tip-burn and powdery mildew symptoms in coriander (Coriandrum sativum) for indoor environment using an edge device** | Parwit Chutichaimaytar, Zhang Zongqi, Kriengkri Kaewtrakulpong, Tofael Ahamed,Smart Agricultural Technology (2025)                                     | **Mengembangkan model***deep learning*yang ditingkatkan ( **CTB-YOLO** **) untuk deteksi dini gejala***tip-burn*dan*powdery mildew*pada daun ketumbar yang dibudidayakan di dalam ruangan, dengan fokus pada pengurangan*false-positive*(FP). | **CTB-YOLO**mencapai mAP50 76.1% untuk*tip-burn*dan 69.3% untuk *powdery mildew* **, secara signifikan mengurangi deteksi** *false-positive* **.**^63^Model diterapkan pada perangkat*edge*dan menyediakan notifikasi*real-time*(LINE).^64^                                                                       | **Model quantization (8-bit) tidak memberikan perbaikan kecepatan inferensi pada Raspberry Pi 4B.**^65^Keterbatasan data dalam variabilitas spektral (semua dikumpulkan di bawah pencahayaan yang konsisten) dapat mempengaruhi generalisasi model.^66^                             | **CTB-YOLO**mencapai mAP50 76.1% (tertinggi di antara model yang dibandingkan) dan*recall*71.0%, dengan akurasi sempurna dalam menghindari*false-positive*pada deteksi *tip-burn* **.** |

| **Judul**                                                                                                                                    | **Peneliti, Media Publikasi dan Tahun**                                                                                                                     | **Tujuan Penelitian**                                                                                                                                                                                                                                                                          | **Kesimpulan**                                                                                                                                                                                                                                                                                                                              | **Saran atau Kelemahan**                                                                                                                                                                                                                                               | **Perbandingan**                                                                                                                                                                                                                                   |
| -------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **RSD-YOLO: An improved YOLOv7-tiny framework for oat disease severity identification with integration of ReXNet and decoupled head**        | Yongquan Zhang, Yiwei Xu, Taosheng Xu, Changmiao Wang, Chengdao Li, Hai Wang,*Smart Agricultural Technology*(2025)                                              | Mengatasi tingginya biaya komputasi dan akurasi yang rendah pada identifikasi tingkat keparahan penyakit gandum (oat) di lingkungan terbatas sumber daya dengan mengusulkan model**RSD-YOLO**berbasis YOLOv7-tiny.                                                                             | **RSD-YOLO**(6.5M parameter, 11.2 GFLOPs) mencapai presisi 91.6%,*recall*90.8%, dan mAP@0.5 88.5%, melampaui*baseline*YOLOv7-tiny hingga 10%^1^^1^^1^^1^.**Model menunjukkan kinerja lebih tinggi dengan biaya komputasi lebih rendah dibandingkan model yang lebih besar dan***lightweight*lainnya^2^^2^^2^^2^^2^^2^^2^^2^^2^. | **Efektivitas model bergantung pada kualitas dataset yang dikumpulkan dalam kondisi terkontrol, yang sulit dijamin di lapangan**^3^.**Perlu optimasi lebih lanjut (** *pruning* **,** *quantization* **) untuk***deployment*skala besar^4^.    | **RSD-YOLO**(11.2 GFLOPs, 6.5M Params) mencapai mAP@0.5 88.5%, melampaui YOLOv11s (21.3 GFLOPs, 9.4M Params, 84.7% mAP@0.5) dan YOLOv5s (15.8 GFLOPs, 7.1M Params, 83.4% mAP@0.5)^5^^5^^5^^5^^5^^5^^5^^5^^5^.                                      |
| **GCD-YOLO: A deep learning network for accurate tomato fruit stalks identification in unstructured environments**                           | Wuxiong Weng, Zhenhui Lai, Zheming Cui, Zhixiong Chen, Hongbin Chen, Tianliang Lin, Jufei Wang, Shuhe Zheng, Guoqing Chen,*Smart Agricultural Technology*(2025) | Mengidentifikasi tangkai buah tomat secara akurat di lingkungan lapangan yang tidak terstruktur untuk operasi pemotongan robotik, dengan mengusulkan model**GCD-YOLO**yang ditingkatkan dari YOLOv8n.                                                                                          | **GCD-YOLO**mencapai presisi 94.4% dan mAP@50 91.7% untuk tangkai buah tomat^6^^6^^6^^6^.**Model mencapai kecepatan inferensi 26.24 FPS pada perangkat***edge*NVIDIA Jetson Orin Nano di lapangan^7^^7^^7^^7^^7^^7^^7^^7^^7^.                                                                                                       | **Tantangan utama adalah proses pembuatan***dataset*yang memakan waktu dan kebutuhan untuk mengatasi oklusi parah melalui sistem*multi-sensor collaborative*^8^^8^^8^^8^.                                                                                          | **GCD-YOLO**(2.389M Params, 7.5 GFLOPs) mengungguli Faster R-CNN (12.0 FPS, 62.9% P), RT-DETR (35.8 FPS, 76.8% P), dan model YOLO terbaru (YOLOv12n 91.4% P) dalam presisi dan efisiensi^9^^9^^9^^9^^9^^9^^9^^9^^9^.                               |
| **WTAD-YOLO: A lightweight tomato leaf disease detection model based on YOLO11**                                                             | Jiangjun Yao, Yiming Li, Zhengyan Xia, Pengcheng Nie, Xuehan Li, Zhe Li,*Smart Agricultural Technology*(2025)                                                   | **Mengatasi tantangan deteksi lesi kecil dan konsumsi sumber daya komputasi yang tinggi pada model***deep learning*untuk deteksi penyakit daun tomat, dengan mengusulkan model**WTAD-YOLO**berbasis YOLO11^10^^10^^10^^10^.                                                            | **WTAD-YOLO**(2.32M parameter, 6.3 GFLOPs) mencapai mAP@0.5 0.917 dan F1-score 0.891^11^^11^^11^^11^.**Dibandingkan YOLO11, mAP@0.5 dan F1-score meningkat 1.9% dan 2.0%, dengan pengurangan parameter sekitar 10.0%**^12^^12^^12^^12^.                                                                                               | *Dataset*saat ini terbatas pada wilayah dan kondisi yang relatif seragam^13^.**Belum divalidasi pada jenis tanaman atau penyakit lain**^14^.**Daun sehat cenderung salah diklasifikasikan sebagai***background*^15^^15^^15^^15^.                             | **WTAD-YOLO**(6.3 GFLOPs) melampaui YOLO11 ( *baseline* **, 6.3 GFLOPs) dalam mAP@0.5 (0.917 vs 0.898) dan F1-score (0.891 vs 0.871)**^16^^16^^16^^16^.                                                                                    |
| **Optimizing power system edge computing with a high-performance and light-weight YOLO-based substation equipment defect detection network** | Qian Wang, Rui Liu, Sichen Qin, Jiawei Pu, Rong Shi, Yulu Wang,*Electrical Power and Energy Systems*(2025)                                                      | **Mengatasi tantangan multi-objek deteksi cacat peralatan gardu induk (kualitas sampel tidak seimbang, oklusi, diskriminasi objek-latar belakang yang buruk) di** *edge computing* **, dengan mengusulkan model****YOLO-SS-tiny**berbasis YOLOv5n^17^^17^^17^^17^^17^^17^^17^^17^^17^. | **YOLO-SS-tiny**mengurangi total*loss*sebesar 24.34%, mencapai mAP 69.1% (6.5% lebih tinggi dari model asli), dan kecepatan deteksi 274.2 FPS, dengan peningkatan parameter sepertiga dari model asli^18^.                                                                                                                                | **Model masih memerlukan perbaikan di masa depan untuk target fitur, lingkungan** *background* **, dan skenario yang berbeda**^19^.                                                                                                                            | **YOLO-SS-tiny**(2.35M Params) mencapai mAP 69.1% dan 274.2 FPS, melampaui YOLOv5n ( *baseline* **, 1.78M Params, 62.6% mAP) dan YOLOv5s (7.05M Params, 67.4% mAP)**^20^^20^^20^^20^.                                                      |
| **DMP-YOLO: Dense multi-scale perception for complex scenes YOLO algorithm Prunus humilis small target detection**                           | Linyou Lv, Jiahui Li, Yan Zhao,*Smart Agricultural Technology*(2025)                                                                                            | **Mengatasi tantangan akurasi deteksi rendah dan kehilangan target pada buah***Prunus humilis*kecil*multi-scale*di bawah oklusi parah, dengan mengusulkan model**DMP-YOLO**berbasis YOLOv8^21^^21^^21^^21^^21^^21^^21^^21^^21^.                                                      | **Di bawah pencahayaan normal,****DMP-YOLO**mencapai akurasi deteksi rata-rata 73.5%, melampaui YOLO-v8 sebesar 14.3%^22^.**Kecepatan inferensi 0.9 ms per gambar, memenuhi persyaratan***real-time*^23^^23^^23^.                                                                                                                   | **Keterbatasan utama adalah jumlah parameter model dan kompleksitas komputasi yang tinggi (GFLOPs tinggi), berpotensi menimbulkan tantangan***deployment*pada perangkat keras terbatas sumber daya^24^.                                                              | **Di bawah pencahayaan normal,****DMP-YOLO**(73.5% mAP50) mengungguli YOLO-v8 (59.2% mAP50) sebesar 14.3%^25^.**Kecepatan inferensi****DMP-YOLO**(0.9 ms) adalah yang tercepat^26^.                                                    |
| **A comprehensive review on YOLO versions for object detection**                                                                             | Ayşe Aybilge Murat, Mustafa Servet Kiran,*Engineering Science and Technology, an International Journal*(2025)                                                  | **Menganalisis versi utama algoritma YOLO (YOLOv1 hingga YOLOv11) secara sistematis untuk mengisi kesenjangan literatur mengenai inovasi arsitektur dan perbandingan versia terbaru**^27^^27^^27^^27^.                                                                                         | **Versi YOLO berupaya menyeimbangkan kecepatan dan akurasi, dengan inovasi terbaru (YOLOv9, YOLOv10, YOLOv11) berfokus pada mengatasi** *information loss* **,** *NMS-free* **, dan***Oriented Bounding Boxes*(OBB)^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^^28^.                                  | **Arsitektur YOLO yang lebih baru (setelah YOLOv8) memiliki kompleksitas tinggi sehingga sulit disesuaikan dan diintegrasikan ke perangkat***end*^29^^29^^29^^29^^29^^29^^29^^29^^29^.**Diperlukan arsitektur yang lebih ringan untuk perangkat***edge*^30^. | **Menyajikan perbandingan historis evolusi YOLO (YOLOv1-YOLOv11), menyoroti peningkatan arsitektur dan metrik performa model skala terbesar**^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^^31^. |
